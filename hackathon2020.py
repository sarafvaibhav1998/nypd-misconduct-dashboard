# -*- coding: utf-8 -*-
"""Hackathon2020.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F6pZ2Wvxeio8bH2cE5-5zUBuIRfO0CwM
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import time
import os
from tqdm import tqdm
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler, MinMaxScaler

allegations = pd.read_csv('/content/drive/My Drive/NYPD-Misconduct-Complaint-Database/allegations_20200726939.csv')

allegations.head()

plt.hist([allegations.unique_mos_id.value_counts()], bins = 7)
plt.show()

columns = ['month_received', 'year_received', 'month_closed', 'year_closed', 'rank_incident', 'mos_ethnicity', 'mos_gender', 'mos_age_incident', 'complainant_ethnicity', 'complainant_gender', 'complainant_age_incident', 'fado_type', 'precinct']

ml_data = allegations[columns]

ml_data.head()

ml_data.shape

ml_data.isnull().sum()

ml_data = ml_data.dropna()

ml_data.shape

ml_data.head()

ml_data = ml_data.assign(Total_Months = (ml_data.year_closed - ml_data.year_received) * 12 + (ml_data.month_closed - ml_data.month_received))

ml_data = ml_data.drop(['month_received', 'year_received', 'month_closed', 'year_closed'], axis = 1)

ml_data.head()

ml_data.dtypes

for column in ['rank_incident', 'mos_ethnicity', 'mos_gender', 'complainant_gender', 'complainant_ethnicity', 'fado_type', 'precinct']:
  ml_data[column] = ml_data[column].astype('category')

ml_data['complainant_gender'].value_counts()

ml_data.head()

ml_data['fado_type'].value_counts()

ml_data['complainant_ethnicity'].value_counts()

ethnicity_mapping = {
    'Black': 0,
    'Asian': 1,
    'Hispanic': 2,
    'White': 3,
    'American Indian': 4,
    'Refused': 5,
    'Other Race': 6,
    'Unknown': 7
}

gender_mapping_complainant = {
    'Male': 0,
    'Female': 1,
    'Not described': 2,
    'Transwoman (MTF)': 3,
    'Transman (FTM)': 4,
    'Gender non-conforming': 5
}

gender_mapping_mos = {
    'M': 0,
    'F': 1
}

rank_mapping = {'Police Officer': 0,
                'Sergeant': 1,
                'Detective': 2,
                'Lieutenant': 3,
                'Captain': 4,
                'Deputy Inspector': 5,
                'Inspector': 6,
                'Chiefs and other ranks': 7
                }

fado_mapping = {
    'Abuse of Authority': 0,
    'Force': 1,
    'Discourtesy': 2,
    'Offensive Language': 3
}

ml_data['complainant_ethnicity'] = ml_data['complainant_ethnicity'].map(ethnicity_mapping)
ml_data['complainant_gender'] = ml_data['complainant_gender'].map(gender_mapping_complainant)
ml_data['fado_type'] = ml_data['fado_type'].map(fado_mapping)
ml_data['rank_incident'] = ml_data['rank_incident'].map(rank_mapping)
ml_data['mos_ethnicity'] = ml_data['mos_ethnicity'].map(ethnicity_mapping)
ml_data['mos_gender'] = ml_data['mos_gender'].map(gender_mapping_mos)

ml_data.head()

ml_data.dtypes

ml_data['complainant_gender'] = ml_data['complainant_gender'].astype(int)

ml_data.head()

ml_data['precinct'].value_counts()

import lightgbm as lgb
from lightgbm import *

X = ml_data.drop(['Total_Months'], axis=1)
Y = ml_data['Total_Months']

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, shuffle=True)

scaler = StandardScaler()

scaler.fit(X_train)

X_train = pd.DataFrame(scaler.transform(X_train))
X_test = pd.DataFrame(scaler.transform(X_test))

Y_train = pd.DataFrame(np.log(Y_train))
Y_test = pd.DataFrame(np.log(Y_test))

lgb_train = lgb.Dataset(X_train, Y_train)
lgb_eval = lgb.Dataset(X_test, Y_test, reference=lgb_train)

reg = lgb.LGBMRegressor(reg_lambda=1.0, random_state=0)

params = {
    'boosting_type': 'gbdt',
    'objective': 'regression',
    'metric': {'l2', 'l1'},
    'verbose': 1,
    'reg_lambda': 1.0,
    'random_state': 0}

print('Starting training...')
# train
gbm = lgb.train(params,
                lgb_train,
                num_boost_round=20,
                valid_sets=lgb_eval,
                early_stopping_rounds=5)

y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)

print('The rmse of prediction is:', mean_squared_error(Y_test, y_pred) ** 0.5)

fn = 'model.txt'
lgb.Booster.save_model(filename=fn)

gbm.save_model('lgb_classifier.txt', num_iteration=gbm.best_iteration)

